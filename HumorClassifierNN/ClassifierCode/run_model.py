import numpy as np
from classifier_model import get_model
from gather_data import gather_data
import tensorflow as tf
import pickle
from matplotlib import pyplot as plt
import seaborn as sns
from pandas import read_csv


def run_model(directly=False, data=None):
    """
    Runs the following operations:
    1. Opens stored in "stats.pkl" file, which was generated by gather_data(),
        or from directly compiled data from get_stats()
    2. Splits data into training and test data
    3. Compiles and fits model from get_model(), saves it to "results" folder
    4. Runs model on test data
    5_bins. Outputs graph to results folder
    6. Saves result data to "results/final_data.pkl"
    """

    if directly:
        # Generate data from scratch
        if data is None:
            negative_data = read_csv('datasets/ML_Inter_Puns/negative_data_file.csv', names=['joke', 'funny'])
            Puns_positive_data = read_csv('datasets/ML_Inter_Puns/positive_data_file.csv', names=['joke', 'funny'])
            dataset_name = 'puns'
            train_data, test_data = gather_data(negative_data, Puns_positive_data)
        else:
            train_data, test_data, dataset_name = data
    else:
        # Get data from "stats.pkl" file
        file_name = "stats.pkl"
        open_file = open(file_name, "rb")
        stats = pickle.load(open_file)
        open_file.close()
        train_data, test_data = stats
        dataset_name = 'from .pkl file'

    x = []
    y = []
    j = []
    for i in range(len(train_data)):
        d = train_data[i]
        x.append(d[0])
        y.append(d[1])
        j.append(d[2])

    x_test = []
    y_test = []
    j_test = []
    for i in range(len(test_data)):
        d = test_data[i]
        x_test.append(d[0])
        y_test.append(d[1])
        j_test.append(d[2])

    x = np.asarray(x).astype('float32')
    y = np.asarray(y).astype(int)
    x_test = np.asarray(x_test).astype('float32')
    y_test = np.asarray(y_test).astype(int)

    # Compiles and Trains Model
    print('training dataset: ' + dataset_name)
    model = get_model(x)
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc', tf.keras.metrics.BinaryCrossentropy(
        name="binary_crossentropy", dtype=None)])
    model.fit(x, y, validation_split=0.1, epochs=15, verbose=0)
    model.save('results')
    # Runs model on test data
    predictions = model.predict(x_test).reshape(-1)
    # print(predictions[:10])
    # print(predictions[:, 0].flatten())
    jokes = []
    for joke in test_data:
        jokes.append(joke[3])

    predictions = np.vstack([predictions, ((predictions >= 0.5).astype(int) == y_test).astype(int)])

    # predictions2 = np.vstack([predictions, ((predictions >= 0.5).astype(int) == y_test).astype(int), jokes])
    # correct2 = []
    # incorrect2 = []
    # print(predictions2.shape)
    # for i in range(predictions2.shape[1]):
    #     prediction2 = predictions2[2, i]
    #     if predictions2[1, i] == '1':
    #         correct2.append(prediction2)
    #     else:
    #         incorrect2.append(prediction2)
    #
    # print('correct: ' + str(correct2))
    # print('\n**************************\nincorrect: ' + str(incorrect2))
    correct = predictions[:, predictions[1] == 1][0]
    incorrect = predictions[:, predictions[1] == 0][0]

    # print('correct: ' + str(correct))
    # print('\n')
    # print('incorrect: ' + str(incorrect))
    # Output graph
    sns.kdeplot(correct, common_norm=True, color='green', label='correct', fill=True)
    sns.kdeplot(incorrect, common_norm=True, color='red', label='incorrect', fill=True)
    plt.legend()
    plt.title("Novel Classifier KDE Plot, dataset: " + dataset_name)
    plt.xlabel("Confidence")
    plt.ylabel("Density")
    plt.savefig("results/kdeplot_" + dataset_name + ".png")

    # # Output graph displot
    # sns.displot(
    #     data=[correct, incorrect],
    #     common_norm=True,
    #     # hue_order=(0, 1),
    #     # kind="kde",
    #     multiple="fill",
    #     # palette="ch:rot=-.25,hue=1,light=.75",
    #     label=("correct", "incorrect"),
    # )
    plt.clf()
    plt.hist(correct, bins=10, density=True, label='correct', color='green')
    plt.hist(incorrect, bins=10, density=True, label='incorrect', color='red')

    # plt.xlim([0.3, .7])
    plt.legend()
    plt.title("Novel Classifier Histogram, dataset: " + dataset_name)
    plt.xlabel("Confidence")
    plt.ylabel("Density")
    plt.savefig("results/hist_" + dataset_name + ".png")
    plt.clf()


    correct = np.array(sorted(correct))
    incorrect = np.array(sorted(incorrect))
    predictions = predictions[:, predictions[0, :].argsort()]
    print('Stats for dataset: ' + dataset_name)
    print('Entire dataset % Correct: ' + str(correct.shape[0]*100/(correct.shape[0]+incorrect.shape[0])))


    correct5 = predictions[:, -5:][:, predictions[1][-5:] == 1].shape[1]*100/5
    correct10 = predictions[:, -10:][:, predictions[1][-10:] == 1].shape[1]*100/10
    correct20 = predictions[:, -20:][:, predictions[1][-20:] == 1].shape[1]*100/20
    std_devpt2 = predictions[:, np.argwhere(predictions[0] >= np.max(predictions[0])-np.std(predictions[0])*0.2)]
    std_devpt5 = predictions[:, np.argwhere(predictions[0] >= np.max(predictions[0])-np.std(predictions[0])*0.5)]
    std_dev = predictions[:, np.argwhere(predictions[0] >= np.max(predictions[0])-np.std(predictions[0]))]
    pct_1 = predictions[:, -int(.1*predictions.shape[1]):]
    pct_05 = predictions[:, -int(.05 * predictions.shape[1]):]
    pct_01 = predictions[:, -int(.01 * predictions.shape[1]):]
    print('\nTop 20, in pct correct: ' + str(correct20))
    print('Top 10, in pct correct: ' + str(correct10))
    print('Top 5_bins, in pct correct: ' + str(correct5))

    print('\nTop 10 percent, in pct correct: ' + str(pct_1[:, pct_1[1]==1].shape[1]*100/pct_1.shape[1]))
    print('Top 5_bins percent, in pct correct: ' + str(pct_05[:, pct_05[1] == 1].shape[1] * 100 / pct_05.shape[1]))
    print('Top 1 percent, in pct correct: ' + str(pct_01[:, pct_01[1] == 1].shape[1] * 100 / pct_01.shape[1]))

    print('\nTop 1 std dev, in pct correct: ' + str(std_dev[:, std_dev[1] == 1].shape[1]*100/std_dev.shape[1]))
    print('Top .5_bins std dev, in pct correct: ' + str(std_devpt5[:, std_devpt5[1] == 1].shape[1]*100/std_devpt5.shape[1]))
    print('Top .2 std dev, in pct correct: ' + str(std_devpt2[:, std_devpt2[1] == 1].shape[1]*100/std_devpt2.shape[1]))

    print('\nTotal results:')
    print(str(correct.shape[0]*100/(correct.shape[0]+incorrect.shape[0])))
    print(str(correct20))
    print(str(correct10))
    print(str(correct5))
    print(str(pct_1[:, pct_1[1]==1].shape[1]*100/pct_1.shape[1]))
    print(str(pct_05[:, pct_05[1] == 1].shape[1] * 100 / pct_05.shape[1]))
    print(str(pct_01[:, pct_01[1] == 1].shape[1] * 100 / pct_01.shape[1]))
    print(str(std_dev[:, std_dev[1] == 1].shape[1]*100/std_dev.shape[1]))
    print(str(std_devpt5[:, std_devpt5[1] == 1].shape[1]*100/std_devpt5.shape[1]))
    print(str(std_devpt2[:, std_devpt2[1] == 1].shape[1]*100/std_devpt2.shape[1]))
    # Save results in pickle file "results/final_data.pkl"
    final_data = (train_data, test_data, predictions, correct, incorrect)
    file_name = "results/final_data_" + dataset_name + ".pkl"
    open_file = open(file_name, "wb")
    pickle.dump(final_data, open_file)
    open_file.close()
